{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a9483b",
   "metadata": {},
   "source": [
    "# Purpose:\n",
    "-> To create another AI model, now, more complex. Content explained on the previous notebook will not be covered here.\n",
    "\n",
    "Topic: Clustering\n",
    "\n",
    "About the used Data: I have imported them from the Keras, it has a lot of data about flowers. They are not pictures, they are just numeric information. At the end, my model will be able to identify the Specie of the flower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecda246",
   "metadata": {},
   "source": [
    "# What are Clusters?\n",
    "-> Group of similar items that are grouped together. In data science and machine learning, clustering is a technique used for unsupervised learning used to identify natural groupings in data without pre-labeled outcomes.\n",
    "\n",
    "Steps for clustering:\n",
    "1- Randomly pick K points to place K centroids\n",
    "2- Assign all the data points to the centroids by distance. The closest centroid to a point is the one it is assigned to.\n",
    "3- Average all the points belonging to each centroid to find the middle of those clusters (center of mass). Place the corresponding centroids into that position.\n",
    "4- Reassign every point once again to the closest centroid.\n",
    "5- Repeat steps 3-4 until no point changes which centroid it belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77696b8",
   "metadata": {},
   "source": [
    "# Hidden Markov Models (HMM)\n",
    "Statitical models used to represent systems that evolve by the time, but the real state of the system is not directly observable (hidden). In order to know the state of it, we have to see the emissions. Before continuing, lets see some key concepts:\n",
    "\n",
    "Hidden states: The real state of the system that we can not see directly, for example: Humor of someone (Happy, sad, neutral...)\n",
    "Observations: The data we can see that may indicate the state, for example: What that person said\n",
    "States Trasactions: The probabilities of the system to change a state to another state. Example: Happiness turns sadness.\n",
    "Emissions probabilities: The probabilities of seeing a specific observation.\n",
    "Initial state: Probabilies associated to start in a determined state\n",
    "\n",
    "What the HMM does, is to model sequences of temporal events, where there is a chain of dependencies between events. It also estimates what is the most probable sequence of states between the hidden states. The HMM is often used to: Speech recognization, Processment of Natural Language, biological computation and prevision of future value of a dataset\n",
    "\n",
    "Im summary, to predict the future based on the past."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ed5ed",
   "metadata": {},
   "source": [
    "# About the data:\n",
    "I will be importing the data from TensorFlow documentation. This dataset will give me data about the weather of some previous days.\n",
    "Important informations of the dataset: \n",
    "1- Cold days are indicated by 0 and hot days by 1\n",
    "2- The first day of the sequence has an 80% chance of being cold\n",
    "3- A cold day has a 30% chance of being followed by a hot day\n",
    "4- A hot day has a 20% chance of being followed by a cold day\n",
    "5- On each day the temperature is normally distributed with mean and standard deviation 0 and 5 on a cold day and mean and standard deviation 15 and 10 on a hot day\n",
    "\n",
    "Standard deviation: The amount the value can varie (either + or -)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ca49aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing:\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebe7ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions # Making a shortcut\n",
    "initial_distribution = tfd.Categorical(probs=[0.8, 0.2]) # The chances of starting at each state. The amount of values in the list\n",
    "                                                        # indicates the amount of states\n",
    "\n",
    "transition_distribution = tfd.Categorical(probs=[[0.5, 0.5], [0.2, 0.8]]) # The chances of moving to another state of staying on the same\n",
    "                                                                        # the amount of brackets indise the main bracket must match the amount of states. The first number of the inner bracket means the chance of maintaing the state and the second value means to move to the other state. Also, the amount of values into the inner brackets must match the amount of states.\n",
    "\n",
    "observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.]) # The loc is the mean (in this case, the avarage temperature) of each \n",
    "                                                                        # state. The scale is the deviation of the loc (in this case, -5 degrees to 5 degrees...). Notice that loc[0] is talking about the same state that scale[0]. The amount of data inside both lists, must match the amount of states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7476f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model:\n",
    "model = tfd.HiddenMarkovModel(\n",
    "    initial_distribution=initial_distribution,\n",
    "    transition_distribution=transition_distribution,\n",
    "    observation_distribution=observation_distribution,\n",
    "    num_steps=7 #How many predictions the model wil do.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39fd5ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.        8.4      10.02     10.506    10.651799 10.69554  10.708661]\n"
     ]
    }
   ],
   "source": [
    "mean = model.mean()\n",
    "\n",
    "# Since TensorFlow works by graphing computations on sessions, that what we are doing.\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(mean.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
